{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4d684172-4b94-42cf-bda2-e11952420d86",
      "metadata": {
        "id": "4d684172-4b94-42cf-bda2-e11952420d86"
      },
      "source": [
        "# Homework 10\n",
        "#### Course Notes\n",
        "**Language Models:** https://github.com/rjenki/BIOS512/tree/main/lecture17  \n",
        "**Unix:** https://github.com/rjenki/BIOS512/tree/main/lecture18  \n",
        "**Docker:** https://github.com/rjenki/BIOS512/tree/main/lecture19"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d839a5ba-62f4-4699-baea-018afda70786",
      "metadata": {
        "id": "d839a5ba-62f4-4699-baea-018afda70786"
      },
      "source": [
        "## Question 1\n",
        "#### Make a language model that uses ngrams and allows the user to specify start words, but uses a random start if one is not specified."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ef37d3a-a6ad-42ae-9e16-7d7338c9ce49",
      "metadata": {
        "id": "9ef37d3a-a6ad-42ae-9e16-7d7338c9ce49"
      },
      "source": [
        "#### a) Make a function to tokenize the text."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages(\"tokenizers\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7754MeUkYKq",
        "outputId": "a34a3711-b7a2-469b-f32b-6c49e046cad0"
      },
      "id": "G7754MeUkYKq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependency ‘SnowballC’\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "library(httr)\n",
        "library(tokenizers)\n",
        "library(stringr)\n",
        "\n",
        "tokenize_text <- function(text) {\n",
        "    tokenizers::tokenize_words(text, lowercase=TRUE, strip_punct=TRUE)[[1]]\n",
        "}"
      ],
      "metadata": {
        "id": "R2ry-7GvkNYW"
      },
      "id": "R2ry-7GvkNYW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "86145513-294b-4894-a02c-8ae60e2c616e",
      "metadata": {
        "id": "86145513-294b-4894-a02c-8ae60e2c616e"
      },
      "source": [
        "#### b) Make a function generate keys for ngrams."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "key_from <- function(ngram, sep = \"\\x1f\") {\n",
        "    paste(ngram, collapse=sep)\n",
        "}"
      ],
      "metadata": {
        "id": "HZm3IoVxlcxc"
      },
      "id": "HZm3IoVxlcxc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "52988c2c-b230-467f-b519-72bc85b93b43",
      "metadata": {
        "id": "52988c2c-b230-467f-b519-72bc85b93b43"
      },
      "source": [
        "#### c) Make a function to build an ngram table."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "build_ngram_table <- function(tokens, n, sep = \"\\x1f\") {\n",
        "    if (length(tokens) < n) return(new.env(parent = emptyenv()))\n",
        "    tbl <- new.env(parent = emptyenv())\n",
        "    for (i in seq_len(length(tokens) - n + 1L)) {\n",
        "        ngram <- tokens[i:(i + n - 2L)]\n",
        "        next_word <- tokens[i + n - 1L]\n",
        "        key <- paste(ngram, collapse = sep)\n",
        "        counts <- if (!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n",
        "        if (next_word %in% names(counts)) {\n",
        "            counts[[next_word]] <- counts[[next_word]] + 1L\n",
        "        } else {\n",
        "            counts[[next_word]] <- 1L\n",
        "        }\n",
        "        tbl[[key]] <- counts\n",
        "    }\n",
        "    tbl\n",
        "}"
      ],
      "metadata": {
        "id": "czP2fTYNmQsF"
      },
      "id": "czP2fTYNmQsF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1ca6db37-abce-4705-9784-e1b898174f00",
      "metadata": {
        "id": "1ca6db37-abce-4705-9784-e1b898174f00"
      },
      "source": [
        "#### d) Function to digest the text."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "digest_text <- function(text, n) {\n",
        "    tokens <- tokenize_text(text)\n",
        "    build_ngram_table(tokens, n)\n",
        "}"
      ],
      "metadata": {
        "id": "9XjhS26dmRwJ"
      },
      "id": "9XjhS26dmRwJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "53fff313-0f13-479b-94df-7588c19fdd3d",
      "metadata": {
        "id": "53fff313-0f13-479b-94df-7588c19fdd3d"
      },
      "source": [
        "#### e) Function to digest the url."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "digest_url <- function(url, n) {\n",
        "    res <- httr::GET(url)\n",
        "    txt <- httr::content(res, as = \"text\", encoding = \"UTF-8\")\n",
        "    digest_text(txt,n)\n",
        "}"
      ],
      "metadata": {
        "id": "cfApTrDbmTKb"
      },
      "id": "cfApTrDbmTKb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c4aa4e73-ee6f-4569-9a54-9d7f7eb3f80a",
      "metadata": {
        "id": "c4aa4e73-ee6f-4569-9a54-9d7f7eb3f80a"
      },
      "source": [
        "#### f) Function that gives random start."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_start <- function(tbl, sep = \"\\x1f\") {\n",
        "    keys <- ls(envir = tbl, all.names=TRUE)\n",
        "    if (length(keys)==0) stop(\"No n-grams available. Digest text first.\")\n",
        "    picked <- sample(keys, 1)\n",
        "    strsplit(picked, sep, fixed=TRUE)[[1]]\n",
        "}"
      ],
      "metadata": {
        "id": "99w-NaTZmU2P"
      },
      "id": "99w-NaTZmU2P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e998fb24-f2d6-41bc-a751-1f6accd3411f",
      "metadata": {
        "id": "e998fb24-f2d6-41bc-a751-1f6accd3411f"
      },
      "source": [
        "#### g) Function to predict the next word."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_next_word <- function(tbl, ngram, sep = \"\\x1f\") {\n",
        "    key <- paste(ngram, collapse = sep)\n",
        "    counts <- if(!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n",
        "    if (length(counts) == 0) return(NA_character_)\n",
        "    sample(names(counts), size=1, prob=as.numeric(counts))\n",
        "}"
      ],
      "metadata": {
        "id": "Sy700RIHmWWf"
      },
      "id": "Sy700RIHmWWf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "347f4002-4932-42c4-a4af-8689293a5857",
      "metadata": {
        "id": "347f4002-4932-42c4-a4af-8689293a5857"
      },
      "source": [
        "#### h) Function that puts everything together. Specify that if the user does not give a start word, then the random start will be used."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_ngram_generator <- function(tbl, n, sep = \"\\x1f\") {\n",
        "    force(tbl); n <- as.integer(n); force(sep)\n",
        "    function(start_words = NULL, length = 10L) {\n",
        "        if ((is.null(start_words)) || length(start_words) != n - 1L) {\n",
        "            start_words <- random_start(tbl, sep=sep)\n",
        "        }\n",
        "        word_sequence <- start_words\n",
        "        for (i in seq_len(max(0L, length - length(start_words)))) {\n",
        "            ngram <- tail(word_sequence, n - 1L)\n",
        "            next_word <- predict_next_word(tbl, ngram, sep=sep)\n",
        "            if (is.na(next_word)) break\n",
        "            word_sequence <- c(word_sequence, next_word)\n",
        "        }\n",
        "        paste(word_sequence, collapse= \" \")\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "tFo_p9pamX_Z"
      },
      "id": "tFo_p9pamX_Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "3b742c67-907c-4bc7-8df1-c84fa65a7554",
      "metadata": {
        "id": "3b742c67-907c-4bc7-8df1-c84fa65a7554"
      },
      "source": [
        "## Question 2\n",
        "#### For this question, set `seed=2025`.\n",
        "#### a) Test your model using a text file of [Grimm's Fairy Tails](https://www.gutenberg.org/cache/epub/2591/pg2591.txt)\n",
        "#### i) Using n=3, with the start word(s) \"the king\", with length=15.\n",
        "#### ii) Using n=3, with no start word, with length=15."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(seed = 2025)\n",
        "\n",
        "url <- \"https://www.gutenberg.org/cache/epub/2591/pg2591.txt\"\n",
        "tbl3 <- digest_url(url, n=3)\n",
        "gen3 <- make_ngram_generator(tbl3, n=3)"
      ],
      "metadata": {
        "id": "Rn2e5PQXmlpo"
      },
      "id": "Rn2e5PQXmlpo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b51d16c-e1fc-4040-af83-c24749ef3879",
        "outputId": "08e8822d-b180-432d-aa8a-2c061148124e"
      },
      "source": [
        "print(gen3(start_words = c(\"the\", \"king\"), length = 15))\n"
      ],
      "id": "8b51d16c-e1fc-4040-af83-c24749ef3879",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"the king their leader fawkes who now surrendered himself at coventry was banished from the\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "528b3a03-7b44-4861-807d-5369680ee307",
        "outputId": "93373763-8c41-4ee2-c1f0-697a902a656c"
      },
      "source": [
        "print(gen3(length = 15))"
      ],
      "id": "528b3a03-7b44-4861-807d-5369680ee307",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"a hillock where during the whole of the arbalest of this day had no uniform\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e04b167-7f2c-4e0f-88e7-86ba5e8d74cc",
      "metadata": {
        "id": "0e04b167-7f2c-4e0f-88e7-86ba5e8d74cc"
      },
      "source": [
        "#### b) Test your model using a text file of [Ancient Armour and Weapons in Europe](https://www.gutenberg.org/cache/epub/46342/pg46342.txt)\n",
        "#### i) Using n=3, with the start word(s) \"the king\", with length=15.\n",
        "#### ii) Using n=3, with no start word, with length=15."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url <- \"https://www.gutenberg.org/cache/epub/46342/pg46342.txt\"\n",
        "tbl3 <- digest_url(url, n=3)\n",
        "gen3 <- make_ngram_generator(tbl3, n=3)"
      ],
      "metadata": {
        "id": "NE_Sy6s9oD23"
      },
      "id": "NE_Sy6s9oD23",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(gen3(start_words = c(\"the\", \"king\"), length = 15))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNzgRAQXoQwl",
        "outputId": "b83a665f-6b37-4fb6-cadb-4c8ea0251082"
      },
      "id": "SNzgRAQXoQwl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"the king qe nul c͂hr ne esquier qe serra de meisme l'estat de chevalerie car\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(gen3(length = 15))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "of2rdqqHoS3M",
        "outputId": "a785d5b3-208b-4d13-aadd-77084753234b"
      },
      "id": "of2rdqqHoS3M",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"ardenti nimium prorumpere tandem _vix obstat ferro fabricata patena recocto_ qua bene munierat pectus sibi\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25fb37ad-8e7c-4e62-afc0-ba46d46401fc",
      "metadata": {
        "id": "25fb37ad-8e7c-4e62-afc0-ba46d46401fc"
      },
      "source": [
        "#### c) Explain in 1-2 sentences the difference in content generated from each source."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The biggest difference that is obvious upon a quick glance is that the content generated from one model is in english while the other model outputs text that is in latin."
      ],
      "metadata": {
        "id": "WQWOEypaoVuc"
      },
      "id": "WQWOEypaoVuc"
    },
    {
      "cell_type": "markdown",
      "id": "56e45972-f441-4d07-9073-fcddd6146cbd",
      "metadata": {
        "id": "56e45972-f441-4d07-9073-fcddd6146cbd"
      },
      "source": [
        "## Question 3\n",
        "#### a) What is a language learning model?\n",
        "#### b) Imagine the internet goes down and you can't run to your favorite language model for help. How do you run one locally?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) A Language learning model is a type of model that is trained to generate human language based off of text data that it is trained on. LLMs that are more advanced are able to take in an input and output a response that may match what it is that you originally put in or asked.\n",
        "\n",
        "b) I would be able to run a language learning model locally on my computer using Ollama, although setting it up would require an initial internet connection."
      ],
      "metadata": {
        "id": "0MxnoXUdovNI"
      },
      "id": "0MxnoXUdovNI"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsqeHcBrsb4m"
      },
      "source": [
        "## Question 4\n",
        "#### Explain what the following vocab words mean in the context of typing `mkdir project` into the command line. If the term doesn't apply to this command, give the definition and/or an example.\n",
        "| Term | Meaning |  \n",
        "|------|---------|\n",
        "| **Shell** | The command-line interpreter that is running inside the terminal. It takes in the mkdir project and executes the mkdir program.|\n",
        "| **Terminal emulator** | This is the environment in which one writes the commands into. It emulates a physical terminal and provides you a way to interact with the shell. |\n",
        "| **Process** | A process is a running instance of a program. When a command is input, it creates a process, does its job and then terminates. It then waits for the next command. |\n",
        "| **Signal** | A signal is a way of interrupting any ongoing processes. |\n",
        "| **Standard input** | The default source of input for a process. |\n",
        "| **Standard output** | The default destination for a process's output |\n",
        "| **Command line argument** | additional pieces of information that are provided after the program is named. In this case, project is a command line argument. |\n",
        "| **The environment** | A collection of variable-value pairs that can be used by any process to give additional context. When the mkdir process is started, it gives a copy of the environment to it, which includes variables such as \\$PATH and \\$HOME. |"
      ],
      "id": "gsqeHcBrsb4m"
    },
    {
      "cell_type": "markdown",
      "id": "1332ff27-ca3f-4f7e-b4b9-07ead0358dd2",
      "metadata": {
        "id": "1332ff27-ca3f-4f7e-b4b9-07ead0358dd2"
      },
      "source": [
        "## Question 5\n",
        "#### Consider the following command `find . -iname \"*.R\" | xargs grep read_csv`.\n",
        "#### a) What are the programs?\n",
        "#### b) Explain what this command is doing, part by part."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) There are three programs, find, xargs, and grep.\n",
        "\n",
        "b) This command is first executing the find program to search for R files within the current directory/subdirectories it was ran in and then it prints the full path of each file into a standard output. The pipe operator then takes the standard output from that command and feeds it in as the standard input for the second command. xargs then converts those inputs into a list of command-line arguments which are then read by the grep program to search inside all the r files and find any line that contains the string \"read_csv\"."
      ],
      "metadata": {
        "id": "QnIhSU4-xPuf"
      },
      "id": "QnIhSU4-xPuf"
    },
    {
      "cell_type": "markdown",
      "id": "69771ac7-865e-4d82-aa25-a39e7c1ab095",
      "metadata": {
        "id": "69771ac7-865e-4d82-aa25-a39e7c1ab095"
      },
      "source": [
        "## Question 6\n",
        "#### Install Docker on your machine. See [here](https://github.com/rjenki/BIOS512/blob/main/lecture18/docker_install.md) for instructions.\n",
        "#### a) Show the response when you run `docker run hello-world`.\n",
        "#### b) Access Rstudio through a Docker container. Set your password and make sure your files show up on the Rstudio server. Type the command and the output you get below.\n",
        "#### c) How do you log in to the RStudio server?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) https://gyazo.com/2a1088666e17b616995e3f8fe1ec64b1\n",
        "\n",
        "b) docker run -it -p 8787:8787 rocker/verse\n",
        "\n",
        "output: The password is set to poogoosh1sheeDik\n",
        "If you want to set your own password, set the PASSWORD environment variable. e.g. run with:\n",
        "docker run -e PASSWORD=<YOUR_PASS> -p 8787:8787 rocker/rstudio\n",
        "\n",
        "   https://gyazo.com/12cbf5eee2f21cfd0d1558e573c56633\n",
        "\n",
        "\n",
        "c) You log in by typing in rstudio as the username and whatever password you were given or your custom password if you added the argument."
      ],
      "metadata": {
        "id": "sTD29q32RYaW"
      },
      "id": "sTD29q32RYaW"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "4.3.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}